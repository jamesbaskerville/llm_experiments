{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/baskerville/Development/ll_env/lib/python3.8/site-packages (0.2.0)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.28.0-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Downloading protobuf-5.28.0-cp38-abi3-macosx_10_9_universal2.whl (414 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-5.28.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baskerville/Development/ll_env/lib/python3.8/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 2434\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 215\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 215\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dataset = DatasetDict.load_from_disk(\"./article-titles.hf\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"albert/albert-base-v2\"\n",
    "your_path = 'classify-articles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Distribution: Counter({'science': 497, 'sports': 493, 'economy': 489, 'politics': 480, 'technology': 475})\n",
      "Test Label Distribution: Counter({'sports': 50, 'science': 47, 'politics': 47, 'technology': 36, 'economy': 35})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_label_distribution = Counter(dataset['train']['label'])\n",
    "test_label_distribution = Counter(dataset['test']['label'])\n",
    "\n",
    "print(\"Training Label Distribution:\", train_label_distribution)\n",
    "print(\"Test Label Distribution:\", test_label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(dataset['train']['label'])\n",
    "\n",
    "def encode_labels(example):\n",
    "    return {'encoded_label': label_encoder.transform([example['label']])[0]}\n",
    "\n",
    "for split in dataset:\n",
    "    dataset[split] = dataset[split].map(encode_labels, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID to Label Mapping: {0: 'economy', 1: 'politics', 2: 'science', 3: 'sports', 4: 'technology'}\n",
      "Label to ID Mapping: {'economy': 0, 'politics': 1, 'science': 2, 'sports': 3, 'technology': 4}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "unique_labels = sorted(list(set(dataset['train']['label'])))\n",
    "id2label = {i: label for i, label in enumerate(unique_labels)}\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "\n",
    "# Verify the correct labels\n",
    "print(\"ID to Label Mapping:\", config.id2label)\n",
    "print(\"Label to ID Mapping:\", config.label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c371c3086484be1a7fd6d20f5ca1926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5df1ce9cd7b44c8a620e68c02aee68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d87c795cee4ad6be7d0ed93da7e220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baskerville/Development/ll_env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b199dbf6f44b93affa6de88b800659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertForSequenceClassification, AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "model = AlbertForSequenceClassification.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ef144e9dc34e1ca5f37b34036c4a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f26f9375ee140d3829af1555c442404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d0be311d324713b62fce131dc5b30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057545ccfff64cf086e1f902cf1595e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b56c1826b8440b96efe5c1a2797d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca161adf3d74c0e9162076b9e7bf8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__', 'encoded_label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2434\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__', 'encoded_label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 215\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__', 'encoded_label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 215\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_invalid_content(example):\n",
    "    return isinstance(example['text'], str)\n",
    "\n",
    "dataset = dataset.filter(filter_invalid_content, batched=False)\n",
    "\n",
    "def encode_data(batch):\n",
    "    tokenized_inputs = tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=256)\n",
    "    tokenized_inputs[\"labels\"] = batch[\"encoded_label\"]\n",
    "    return tokenized_inputs\n",
    "\n",
    "dataset_encoded = dataset.map(encode_data, batched=True)\n",
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(unique_labels)\n",
    "\n",
    "def per_label_accuracy(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    correct_predictions = cm.diagonal()\n",
    "    label_totals = cm.sum(axis=1)\n",
    "    per_label_acc = np.divide(correct_predictions, label_totals, out=np.zeros_like(correct_predictions, dtype=float), where=label_totals != 0)\n",
    "    return dict(zip(labels, per_label_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    decoded_labels = label_encoder.inverse_transform(labels)\n",
    "    decoded_preds = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    precision = precision_score(decoded_labels, decoded_preds, average='weighted')\n",
    "    recall = recall_score(decoded_labels, decoded_preds, average='weighted')\n",
    "    f1 = f1_score(decoded_labels, decoded_preds, average='weighted')\n",
    "    acc = accuracy_score(decoded_labels, decoded_preds)\n",
    "\n",
    "    labels_list = list(label_encoder.classes_)\n",
    "    per_label_acc = per_label_accuracy(decoded_labels, decoded_preds, labels_list)\n",
    "\n",
    "    per_label_acc_metrics = {}\n",
    "    for label, accuracy in per_label_acc.items():\n",
    "        label_key = f\"accuracy_label_{label}\"\n",
    "        per_label_acc_metrics[label_key] = accuracy\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        **per_label_acc_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baskerville/Development/ll_env/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a07d1c7bd4d482b84ca0a721caa4baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6592, 'grad_norm': 17.214561462402344, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.13}\n",
      "{'loss': 1.6322, 'grad_norm': 12.780923843383789, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.26}\n",
      "{'loss': 1.5926, 'grad_norm': 30.824169158935547, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.39}\n",
      "{'loss': 1.5943, 'grad_norm': 17.90578842163086, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.52}\n",
      "{'loss': 1.5476, 'grad_norm': 17.254802703857422, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.65}\n",
      "{'loss': 1.5345, 'grad_norm': 23.29121971130371, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.78}\n",
      "{'loss': 1.5421, 'grad_norm': 21.84389305114746, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.92}\n",
      "{'loss': 1.4884, 'grad_norm': 24.690324783325195, 'learning_rate': 3.2000000000000003e-06, 'epoch': 1.05}\n",
      "{'loss': 1.4151, 'grad_norm': 25.043909072875977, 'learning_rate': 3.6000000000000003e-06, 'epoch': 1.18}\n",
      "{'loss': 1.3703, 'grad_norm': 25.61355209350586, 'learning_rate': 4.000000000000001e-06, 'epoch': 1.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f3d53c2e13446daa85cf17c4da5549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.377465844154358, 'eval_accuracy': 0.4930232558139535, 'eval_f1': 0.42383332698769244, 'eval_precision': 0.6099528142905292, 'eval_recall': 0.4930232558139535, 'eval_accuracy_label_economy': 0.8, 'eval_accuracy_label_politics': 0.02127659574468085, 'eval_accuracy_label_science': 0.7021276595744681, 'eval_accuracy_label_sports': 0.72, 'eval_accuracy_label_technology': 0.2222222222222222, 'eval_runtime': 0.9308, 'eval_samples_per_second': 230.989, 'eval_steps_per_second': 15.041, 'epoch': 1.31}\n",
      "{'loss': 1.3219, 'grad_norm': 25.733768463134766, 'learning_rate': 4.4e-06, 'epoch': 1.44}\n",
      "{'loss': 1.2374, 'grad_norm': 19.24130630493164, 'learning_rate': 4.800000000000001e-06, 'epoch': 1.57}\n",
      "{'loss': 1.1398, 'grad_norm': 20.945722579956055, 'learning_rate': 5.2e-06, 'epoch': 1.7}\n",
      "{'loss': 1.049, 'grad_norm': 18.362749099731445, 'learning_rate': 5.600000000000001e-06, 'epoch': 1.83}\n",
      "{'loss': 0.9089, 'grad_norm': 21.393177032470703, 'learning_rate': 6e-06, 'epoch': 1.96}\n",
      "{'loss': 0.7627, 'grad_norm': 20.148643493652344, 'learning_rate': 6.4000000000000006e-06, 'epoch': 2.09}\n",
      "{'loss': 0.5946, 'grad_norm': 37.801212310791016, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.22}\n",
      "{'loss': 0.6173, 'grad_norm': 22.492183685302734, 'learning_rate': 7.2000000000000005e-06, 'epoch': 2.35}\n",
      "{'loss': 0.4892, 'grad_norm': 58.739967346191406, 'learning_rate': 7.600000000000001e-06, 'epoch': 2.48}\n",
      "{'loss': 0.4329, 'grad_norm': 31.867156982421875, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d60ad95b2f4bc4bf1ae357b4fdc8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4494597017765045, 'eval_accuracy': 0.8976744186046511, 'eval_f1': 0.9004308622967181, 'eval_precision': 0.9133808113740947, 'eval_recall': 0.8976744186046511, 'eval_accuracy_label_economy': 0.9428571428571428, 'eval_accuracy_label_politics': 0.8936170212765957, 'eval_accuracy_label_science': 0.9148936170212766, 'eval_accuracy_label_sports': 0.96, 'eval_accuracy_label_technology': 0.75, 'eval_runtime': 0.5691, 'eval_samples_per_second': 377.764, 'eval_steps_per_second': 24.599, 'epoch': 2.61}\n",
      "{'loss': 0.3908, 'grad_norm': 16.43819808959961, 'learning_rate': 8.400000000000001e-06, 'epoch': 2.75}\n",
      "{'loss': 0.3735, 'grad_norm': 8.563356399536133, 'learning_rate': 8.8e-06, 'epoch': 2.88}\n",
      "{'train_runtime': 56.2949, 'train_samples_per_second': 129.71, 'train_steps_per_second': 4.05, 'train_loss': 1.0989631905890347, 'epoch': 2.98}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=228, training_loss=1.0989631905890347, metrics={'train_runtime': 56.2949, 'train_samples_per_second': 129.71, 'train_steps_per_second': 4.05, 'total_flos': 9501472156644.0, 'train_loss': 1.0989631905890347, 'epoch': 2.980392156862745})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=your_path,\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=500,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    save_steps=1000,\n",
    "    gradient_accumulation_steps=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded['train'],\n",
    "    eval_dataset=dataset_encoded['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef32b77297842699f812bf892befa94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.38190317153930664,\n",
       " 'eval_accuracy': 0.9069767441860465,\n",
       " 'eval_f1': 0.9060619059788495,\n",
       " 'eval_precision': 0.9125925762408804,\n",
       " 'eval_recall': 0.9069767441860465,\n",
       " 'eval_accuracy_label_economy': 0.9428571428571428,\n",
       " 'eval_accuracy_label_politics': 0.9574468085106383,\n",
       " 'eval_accuracy_label_science': 0.9361702127659575,\n",
       " 'eval_accuracy_label_sports': 0.96,\n",
       " 'eval_accuracy_label_technology': 0.6944444444444444,\n",
       " 'eval_runtime': 0.6159,\n",
       " 'eval_samples_per_second': 349.062,\n",
       " 'eval_steps_per_second': 22.73,\n",
       " 'epoch': 2.980392156862745}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(your_path)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "pipe = pipeline('text-classification', model='classify-articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Los Angeles area high school student dies after injury at football game\n",
      "Output: sports\n",
      "Title: Jannik Sinner bests American Taylor Fritz for U.S. Open men's title\n",
      "Output: sports\n",
      "Title: 30 people injured in alleged drunk driving incident after man drives into building\n",
      "Output: technology\n",
      "Title: Steve Kornacki: How Harris and Trump are polling in states that could decide the election\n",
      "Output: politics\n",
      "Title: Manhunt underway for suspect in Kentucky mass shooting near highway\n",
      "Output: science\n",
      "Title: Liz Cheney says it's 'not enough' for anti-Trump Republicans to vote for someone other than Harris\n",
      "Output: politics\n",
      "Title: AR-15 recovered near I-75 shooting scene in Kentucky as manhunt continues\n",
      "Output: sports\n",
      "Title: â€˜Beetlejuice Beetlejuiceâ€™ jolts box office with $110 million opening weekend\n",
      "Output: technology\n",
      "Title: Maya Rudolph nabs sixth Emmy and Angela Basset wins her first at Creative Arts Emmys\n",
      "Output: sports\n",
      "Title: Kendrick Lamar will headline Super Bowl LIX halftime show\n",
      "Output: sports\n"
     ]
    }
   ],
   "source": [
    "example_titles = [\n",
    "    \"Los Angeles area high school student dies after injury at football game\",\n",
    "    \"Jannik Sinner bests American Taylor Fritz for U.S. Open men's title\",\n",
    "    \"30 people injured in alleged drunk driving incident after man drives into building\",\n",
    "    \"Steve Kornacki: How Harris and Trump are polling in states that could decide the election\",\n",
    "    \"Manhunt underway for suspect in Kentucky mass shooting near highway\",\n",
    "    \"Liz Cheney says it's 'not enough' for anti-Trump Republicans to vote for someone other than Harris\",\n",
    "    \"AR-15 recovered near I-75 shooting scene in Kentucky as manhunt continues\",\n",
    "    \"â€˜Beetlejuice Beetlejuiceâ€™ jolts box office with $110 million opening weekend\",\n",
    "    \"Maya Rudolph nabs sixth Emmy and Angela Basset wins her first at Creative Arts Emmys\",\n",
    "    \"Kendrick Lamar will headline Super Bowl LIX halftime show\",\n",
    "]\n",
    "\n",
    "for title in example_titles:\n",
    "    result = pipe(title)\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Output: {result[0]['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dadf8d6ed84414da6f1b29a412179ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca0c5c9bd4c4152b03aeb06b7ffb643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ca6c8f249347a0b108277f47b9f19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc123433b8184aa5bbd039f60e069d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7237401dce3741fc888d2cf75245c532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jamesbaskerville/classify-articles/commit/0a830b49b5e61d9d6a591ed5e2994316da5fbd0c', commit_message='jamesbaskerville/classify-article-titles', commit_description='', oid='0a830b49b5e61d9d6a591ed5e2994316da5fbd0c', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"jamesbaskerville/classify-article-titles\")\n",
    "trainer.push_to_hub(\"jamesbaskerville/classify-article-titles\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ll_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
